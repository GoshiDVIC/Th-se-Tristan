\chapter{First Step into the Field of Haptic}
\section{Introduction}
The field of Haptic has emerged as a central area of research and innovation in a constantly evolving technological landscape. While human-machine interaction is at the heart of technological development, the sense of touch has often been overlooked. In contrast, significant attention has been given to enhancing visual and auditory interfaces, neglecting the tactile modality. Derived from the Greek "haptikos," meaning "capable of touching or grasping," haptic is the study of tactile perception and the simulation of touch through technology. This multidisciplinary field combines engineering, psychology, neuroscience, and human-computer interaction elements to create experiences that engage our sense of touch, thereby enriching how we interact with the environment and digital devices.

Touch is an integral part of human perception and communication, crucial in conveying emotions, texture, and spatial information. This is the case for blind individuals who primarily rely on their senses of hearing and touch to understand the world. They use touch to discern objects, navigate, or even read using Braille language [2]. Furthermore, technological innovations based on the sense of touch and haptic are being developed to assist blind individuals [3][4]. It enables us to comprehend the world around us and interact with it.

Aware of this, researchers and engineers strive to harness haptic to bridge the gap between the physical and digital realms.
The growing interest in haptic stems from the desire to create more immersive technological experiences. Traditional interfaces, which rely heavily on visual and auditory senses, often fail to convey depth, material properties, or the feeling of presence that physical interactions offer. Haptic technology can revolutionize how we interact with devices, applications, and virtual environments, as well as provide an alternative mode of interaction for individuals with visual or auditory impairments. Furthermore, as technology extends into areas such as virtual reality and augmented reality and plays a significant role in medicine [5], haptic becomes even more crucial in enabling realistic and impactful experiences.

One of the earliest applications of haptic technology was in early 20th-century light aircraft lacking servo mechanisms. When the aircraft approached a stall, the pilot would feel aerodynamic vibrations through the controls. This served as a valuable warning of dangerous flight conditions [6][7].

The first force feedback game controllers were commercialized in the 1990s, introducing haptic motors into video game controllers, such as with the Nintendo 64 in 1997. These controllers let players feel vibrations corresponding to in-game events, enhancing the gaming experience. The Oculus Rift virtual reality headset, launched in 2013, marked a significant milestone in integrating haptic technology into virtual reality experiences. It revitalized interest in haptic in the video gaming domain [9][10]. It was followed by other virtual reality devices with improved haptic capabilities, such as the HaptX haptic gloves [11].

The 2000s saw the emergence of the first mobile phones equipped with haptic feedback. For example, the Nokia 5800 XpressMusic (2008) provided tactile feedback when using the touchscreen [12]. This was just the initial step in mobile haptic, as it did not allow users to customize the haptic feedback. Currently, haptic feedback is integrated into all our phones, with Apple's Taptic Engine being one of the most prominent [13].

This work aims to make haptic more accessible to the general public to enhance human-machine interaction and add a new dimension of interaction to technologies like prosthetics, for example. Through a series of experiments, the development of DIY kit prototypes, and user testing, it explores the principles of tactile perception, design, components, and the implementation of effective haptic interfaces, along with their impact on the user experience. Finally, several possible applications are presented.

\section{Related Work}

Today, the field of haptic takes many forms, characterized by numerous advances and ongoing projects. It encompasses various aspects, whether it pertains to specific types of haptic, particular sensors, etc.

Some of these projects aim to convey specific effects or forces through haptic, employing various means to achieve this.

The PseudoBend project, developed by Seongkook Heo et al. [15], leverages haptic to create the illusion that a rigid device is being stretched, bent, or twisted. Using haptic motors, the vibrations generated during the deformation of an object are replicated and transmitted to the user. Another possibility for haptic transmission is using sound, as demonstrated by the projects of Donald Degraen et al. [16], who designed vibrotactile feedback in a virtual environment using voice. By swinging a lightsaber in virtual reality (VR), haptic feedback can be felt. Furthermore, Evan Pezent et al.'s project [17] offers a method of controlling vibrotactors based on digital audio interfaces. For all these projects, we refer to them as "vibrotactile feedback." This type of haptic feedback communicates with the user using vibrations to simulate various sensations on the skin.

Some projects focus more on haptic interaction and the human body. The project by Paul Strohmeier and his team [18] aims to improve the design and placement of physical interfaces on the body. They use preprocessed kinesiology tape as touch, pressure, and stretch sensors to determine the most suitable body areas for project designs. TactJam, developed by Dennis Wittchen and his team [19], follows a similar approach.

Other projects focus on sensor development and the types of haptics used.

Piezoelectric sensors are prevalent in many projects and are constantly being improved. For instance, the development of a thick-film piezoelectric sensor for the fingertips of prostheses, carried out by Darryl P. J. Cotton and his team [20], allows users to determine the stability of an object without needing a visual assessment, thus boosting their confidence not to apply excessive force. Mingrino et al. [21] studied a method to detect the onset of slipping of a grasped object. The force sensor used included four thick-film piezoresistive force sensors printed on a polymer film, enabling control of normal and tangential forces and determining the friction coefficient threshold for detecting object slippage. Furthermore, N. Muridan and his team [22] demonstrated that small surface features of an object can be detected using piezoelectric sensors integrated into the fingertips of a prosthesis. On the other hand, cutaneous haptic devices at the fingertips can provide cost-effective and portable solutions. However, they may have limitations regarding credible haptic sensations due to the lack of kinesthetic feedback [23].

Finally, projects related to particular domains are developed to address their needs or improve their processes. A concrete example is the field of virtual reality (VR), which is witnessing significant haptic development [24]. When associated with medicine, it can significantly enhance the efficiency of healthcare. For instance, surgeons can train for complex surgeries in virtual environments with realistic haptic feedback. This force feedback directly impacts the user's muscles, and numerous studies have emphasized the importance of combining haptic in surgery and simulator-based training with haptic feedback [25-30].

On the other hand, patients can benefit from rehabilitation through haptic-based exercises, including engaging projects like that of Mark Sivak and his team [31], which offer a hand rehabilitation system integrating interactive games providing haptic feedback to the user. Furthermore, haptic projects specially designed for amputees contribute to their rehabilitation and social reintegration [32]. Finally, the use of haptic for therapeutic purposes is also an avenue being explored [33].

Despite the wide range of applications and processes, all these techniques remain complex for inexperienced users. They either require the use of expensive hardware, the modification and design of machinery, or extensive knowledge in other fields, such as electronics. The project presented in this chapter does not require advanced electronics or programming knowledge, uses simple and affordable components, and allows for an autonomous prototype.

\section{Concept}
The idea of this chapter is simple: to provide a kit of haptic components for designing various haptic enhancements for prosthetics. Sensors are positioned at the fingertips of a prosthetic device. When the user performs actions, these sensors record data such as applied pressure, object shape, or textures. This data is then processed using various micro-controllers, such as the DRV2605 or Teensy. Subsequently, it is transmitted to a haptic motor that vibrates based on the received information. This haptic motor is in direct contact with the user, allowing them to perceive and receive real-time tactile feedback corresponding to their action.

\section{Evaluation}
The device has been tested with various sensors for different applications. A typical pattern repeats: 

\subsection{Setup}
A sensor is used and placed at the user's fingertip. It is connected to a micro-controller, in this case, a Teensy. The Teensy is linked to the DRV2605 haptic controller, which controls the haptic motors. The LRA or ERM motors must be in contact with the user's skin. Choosing a relatively sensitive skin area is preferable to perceiving the vibrations better.

\subsection{Protocol}
Connect the Teensy to a power source. Launch the code corresponding to the sensor used. The software allows real-time visualization of the recorded data, which helps the user better understand the differences between the vibrations they should feel during the test.

\textit{Simple Piezo Sensor}
To measure the pressure exerted by the user with their fingers. Perform various object manipulations, handling them gently or applying more force, pushing lift different objects. Regarding texture, slide the Piezo sensor on other surfaces; it will generate additional data based on surface variations.

\textit{Flexible Piezo Sensor}
To evaluate the surface of objects and the user's environment. Slide your fingers along surfaces; as soon as they come into contact, the Piezo sensor bends and records data transmitted to the rest of the device.

\textit{Sound Sensor}
Place the sensor at the tip of your fingers and run them over different textures and surfaces. The sound your fingers produce on the material is recorded and transmitted to the controller.

The sensor can be considered functional if the variations in vibrations correspond to the different actions of the user and the displayed data. Currently, the sensors that have shown the most efficiency are the Flexible Piezo types.

\section{Limitations}
Itâ€™s essential to note that this chapter serves as an introduction and may not necessarily represent a significant contribution for individuals with advanced expertise in this field. It aims to remain accessible to a broad audience, whether in innovation and technology, design and engineering, or even economic aspects. That's why it delves deeply into haptic to ensure clear understanding while keeping it simple.

\textit{Hardware}

Currently, the prototype uses only one sensor connected to the micro-controller. The next phase, which involves placing a sensor on each finger of the prosthesis, could pose constraints in power, data reading capacity, and data output. The DRV2605 haptic motor driver controls only one ERM or LRA at a time. The overall size of the components can be excessive, limiting its use for certain prostheses and users. Additionally, the motors used are currently too bulky. The haptic effect becomes much less interesting by reducing the mass and increasing the frequency.

\textit{software}

The current code continuously reads data in real time, which keeps it in constant operation. The accumulation of data and some noise can slow down the entire system.

\section{Future Works}
Innovation in Haptic is still relatively new and represents a path for improvement in engineering. As mentioned earlier, the work presented in this chapter marks a first step and opens the way for numerous potential enhancements.

From a hardware perspective, one improvement for this project is creating a printed circuit board (PCB) to reduce the space occupied by all the components. This is crucial to ensure the efficient use of prosthetics, ensuring that the entire setup is optimal in terms of distance without causing interference or adding extra constraints to the user. Given the rapid evolution in Haptic, it's also essential to stay updated on new components to determine if they might be better suited and more efficient for this project. Using a controller capable of driving multiple DRV2605 devices is worth considering.

There are opportunities to enhance the project on the software front by integrating new features related to the components into the code. By optimizing the code for faster and more efficient operation, it becomes possible to improve the precision of vibrations. Other features associated with the controllers can be explored to optimize the code and offer new functionalities.

\section{Conclusion}
This chapter represents a first step towards understanding and accessing haptic technology. It explores various types of components, their functionalities, and different ways to use them. Furthermore, it offers multiple practical applications and explicit code that everyone can use. It aims to remain simple and accessible to all. The next chapter delves into prosthetics and presents different prototypes for integrating the haptic components introduced in this chapter.